# 🎙️ Speech Emotion Recognition using RAVDESS 🎧

This project explores the **speech modality** of the [RAVDESS dataset](https://www.kaggle.com/datasets/uwrfkaggler/ravdess-emotional-speech-audio) to classify **8 different emotions** from audio signals using various machine learning techniques, including LSTM and Random Forest classifiers.

> 🧠 *It's truly fascinating how deeply our voice alone can reflect human emotions.*


## 🗂️ Dataset

- **Source**: RAVDESS Emotional Speech Audio
- **Platform**: [Kaggle](https://www.kaggle.com/datasets/uwrfkaggler/ravdess-emotional-speech-audio)
- **Subset Used**: 1/7th of the complete dataset
- **Number of Emotions**: 8

---

## 🎛️ Preprocessing Techniques

- Z-score normalization
- Nominal encoding
- Ordinal encoding

---

## 🎙️ Feature Extraction

- **MFCC** (Mel Frequency Cepstral Coefficients)

---

## 🤖 Models and Results

### 🔹 Random Forest Classifier
- Accuracy: ~54% (macro average)

### 🔹 LSTM-based Model
- **Training Accuracy**: ~90%
- **Test Accuracy**: ~70%

> ⚡ Achieved impressive results on a small dataset — highlighting the strength of deep learning in speech emotion recognition.

---

## 📌 Future Work

- Use full RAVDESS dataset for improved generalization
- Try CNN + LSTM hybrid models
- Experiment with data augmentation techniques

---

## 📚 Keywords

`#MachineLearning` `#DeepLearning` `#SpeechRecognition` `#EmotionAI` `#LSTM` `#RAVDESS` `#AI` `#DataScience` `#MFCC` `#NLP`

---

## 📬 Contact

Feel free to reach out if you're interested in collaborating or discussing this project!


